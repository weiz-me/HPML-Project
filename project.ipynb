{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc792ff0-aeaa-4ab8-9a79-c3a86f34c24a",
   "metadata": {},
   "source": [
    "# Part 0 :Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfefbaae-4767-496b-be11-ba86318fae98",
   "metadata": {},
   "source": [
    "### Downloading Data from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55fbfd07-af73-4e0a-8077-a8e70e4b3577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.4-py3-none-any.whl (43 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.0/43.0 KB\u001b[0m \u001b[31m41.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/tqdm/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting tqdm\n",
      "  Downloading tqdm-4.67.0-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 KB\u001b[0m \u001b[31m187.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/wei/.local/lib/python3.10/site-packages (from kagglehub) (24.1)\n",
      "Requirement already satisfied: requests in /home/wei/.local/lib/python3.10/site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/wei/.local/lib/python3.10/site-packages (from requests->kagglehub) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/wei/.local/lib/python3.10/site-packages (from requests->kagglehub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/wei/.local/lib/python3.10/site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/wei/.local/lib/python3.10/site-packages (from requests->kagglehub) (2.2.3)\n",
      "Installing collected packages: tqdm, kagglehub\n",
      "Successfully installed kagglehub-0.3.4 tqdm-4.67.0\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "474973f5-ef9c-4d79-8a93-6059208a2417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming download from 0 bytes (527738644 bytes left)...\n",
      "Resuming download from https://www.kaggle.com/api/v1/datasets/download/gowrishankarp/newspaper-text-summarization-cnn-dailymail?dataset_version_number=2 (0/527738644) bytes left.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 503M/503M [03:28<00:00, 2.54MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/wei/.cache/kagglehub/datasets/gowrishankarp/newspaper-text-summarization-cnn-dailymail/versions/2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"gowrishankarp/newspaper-text-summarization-cnn-dailymail\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86f7fbe2-f338-4fd1-b0f9-9c46cbca2adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r /home/wei/.cache/kagglehub/datasets/gowrishankarp/newspaper-text-summarization-cnn-dailymail/versions/2/cnn_dailymail data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31cb871-e9a2-40a3-9267-358a0c6f3edb",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "698c17cc-683a-4fb3-b8c0-3f9bc68e7baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>article</td>\n",
       "      <td>highlights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001d1afc246a7964130f43ae940af6bc6c57f01</td>\n",
       "      <td>By . Associated Press . PUBLISHED: . 14:11 EST...</td>\n",
       "      <td>Bishop John Folda, of North Dakota, is taking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002095e55fcbd3a2f366d9bf92a95433dc305ef</td>\n",
       "      <td>(CNN) -- Ralph Mata was an internal affairs li...</td>\n",
       "      <td>Criminal complaint: Cop used his role to help ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00027e965c8264c35cc1bc55556db388da82b07f</td>\n",
       "      <td>A drunk driver who killed a young woman in a h...</td>\n",
       "      <td>Craig Eccleston-Todd, 27, had drunk at least t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0002c17436637c4fe1837c935c04de47adb18e9a</td>\n",
       "      <td>(CNN) -- With a breezy sweep of his pen Presid...</td>\n",
       "      <td>Nina dos Santos says Europe must be ready to a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          0  \\\n",
       "0                                        id   \n",
       "1  0001d1afc246a7964130f43ae940af6bc6c57f01   \n",
       "2  0002095e55fcbd3a2f366d9bf92a95433dc305ef   \n",
       "3  00027e965c8264c35cc1bc55556db388da82b07f   \n",
       "4  0002c17436637c4fe1837c935c04de47adb18e9a   \n",
       "\n",
       "                                                   1  \\\n",
       "0                                            article   \n",
       "1  By . Associated Press . PUBLISHED: . 14:11 EST...   \n",
       "2  (CNN) -- Ralph Mata was an internal affairs li...   \n",
       "3  A drunk driver who killed a young woman in a h...   \n",
       "4  (CNN) -- With a breezy sweep of his pen Presid...   \n",
       "\n",
       "                                                   2  \n",
       "0                                         highlights  \n",
       "1  Bishop John Folda, of North Dakota, is taking ...  \n",
       "2  Criminal complaint: Cop used his role to help ...  \n",
       "3  Craig Eccleston-Todd, 27, had drunk at least t...  \n",
       "4  Nina dos Santos says Europe must be ready to a...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !head data/cnn_dailymail/train.csv\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/cnn_dailymail/train.csv', sep=\",\", header=None)\n",
    "df_test = pd.read_csv('data/cnn_dailymail/test.csv', sep=\",\", header=None)\n",
    "df = df.iloc[:10000]\n",
    "df_test = df_test.iloc[:1000]\n",
    "\n",
    "df.to_csv('data/cnn_dailymail/train_short.csv', index=None)\n",
    "df_test.to_csv('data/cnn_dailymail/test_short.csv', index=None)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0e094b8-8022-455c-a70a-7b95929d1a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c34959f2-4618-4036-9ac6-133dfe663d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3521 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max token in col1: 3521\n",
      "Max token in col2: 926\n"
     ]
    }
   ],
   "source": [
    "maxinput_len = df[1].str.len().max()\n",
    "maxoutput_len = df[2].str.len().max()\n",
    "maxinput_tokens = df[df[1].str.len() == maxinput_len][1].apply(lambda x: len(tokenizer.tokenize(x)))\n",
    "maxoutput_tokens = df[df[2].str.len() == maxoutput_len][2].apply(lambda x: len(tokenizer.tokenize(x)))\n",
    "maxinput_tokens=maxinput_tokens.max()\n",
    "maxoutput_tokens = maxoutput_tokens.max()\n",
    "print(\"Max token in col1:\", maxinput_tokens)\n",
    "print(\"Max token in col2:\", maxoutput_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ebb67f3-8723-45ad-b16a-122b1ab9c490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxinput_tokens = df[1].apply(lambda x: len(tokenizer.tokenize(x)))\n",
    "# maxoutput_tokens = df[2].apply(lambda x: len(tokenizer.tokenize(x)))\n",
    "# maxinput_tokens=maxinput_tokens.max()\n",
    "# maxoutput_tokens=maxoutput_tokens.max()\n",
    "# print(f\"{maxinput_tokens=}\")\n",
    "# print(f\"{maxoutput_tokens=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5fba5be-0a5e-4cf7-a751-4828c43f09dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # removing the id fiels\n",
    "# df.column =[\"article\", \"highlights\"]\n",
    "# df.to_csv(\"/data/cnn_dailymail\"\n",
    "# print(f\"{df.shape = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d2520da-ea92-4c89-a4e3-70444aad26d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.46.2-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting datasets\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 KB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 KB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/wei/.local/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 KB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.21,>=0.20\n",
      "  Downloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: requests in /home/wei/.local/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/wei/.local/lib/python3.10/site-packages (from transformers) (2.1.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 KB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /home/wei/.local/lib/python3.10/site-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/wei/.local/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.0/435.0 KB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting dill<0.3.9,>=0.3.0\n",
      "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 KB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp\n",
      "  Downloading aiohttp-3.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.9.0,>=2023.1.0 in /home/wei/.local/lib/python3.10/site-packages (from datasets) (2024.9.0)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 KB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyarrow>=15.0.0\n",
      "  Downloading pyarrow-18.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting multiprocess<0.70.17\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 KB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /home/wei/.local/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 KB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting click\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 KB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.17.0\n",
      "  Downloading yarl-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /home/wei/.local/lib/python3.10/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Collecting aiohappyeyeballs>=2.3.0\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 KB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<6.0,>=4.0\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting propcache>=0.2.0\n",
      "  Downloading propcache-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.9/208.9 KB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /home/wei/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/wei/.local/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/wei/.local/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/wei/.local/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/wei/.local/lib/python3.10/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/wei/.local/lib/python3.10/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/wei/.local/lib/python3.10/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/wei/.local/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: sentencepiece, xxhash, safetensors, regex, pyarrow, propcache, multidict, joblib, frozenlist, dill, click, async-timeout, aiohappyeyeballs, yarl, sacremoses, multiprocess, huggingface-hub, aiosignal, tokenizers, aiohttp, transformers, datasets\n",
      "Successfully installed aiohappyeyeballs-2.4.3 aiohttp-3.11.2 aiosignal-1.3.1 async-timeout-5.0.1 click-8.1.7 datasets-3.1.0 dill-0.3.8 frozenlist-1.5.0 huggingface-hub-0.26.2 joblib-1.4.2 multidict-6.1.0 multiprocess-0.70.16 propcache-0.2.0 pyarrow-18.0.0 regex-2024.11.6 sacremoses-0.1.1 safetensors-0.4.5 sentencepiece-0.2.0 tokenizers-0.20.3 transformers-4.46.2 xxhash-3.5.0 yarl-1.17.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets sentencepiece sacremoses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8733686-d950-4925-ba47-6afaad861e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\")\n",
    "maxinput_tokens = 3521\n",
    "maxoutput_tokens = 926\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b79f28c-9db9-4d4c-a215-bbc120724ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "train_dataset = load_dataset('csv', data_files='data/cnn_dailymail/train_short.csv')\n",
    "test_dataset = load_dataset('csv', data_files='data/cnn_dailymail/test_short.csv')\n",
    "train_dataset = train_dataset.remove_columns(\"0\")\n",
    "test_dataset = test_dataset.remove_columns(\"0\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f096844a-ca50-4a43-8254-e2a50b9b90c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['1', '2'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0c1371d-3864-4b22-b4c9-5a7f6db1fea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['1', '2'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "114b01db-950f-4f5d-9f10-1e7cc8b7ab11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "# checkpoint = 'distilbert-base-cased'\n",
    "# tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96134fc1-863c-436f-835b-416db8453cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"By . Associated Press . PUBLISHED: . 14:11 EST, 25 October 2013 . | . UPDATED: . 15:36 EST, 25 October 2013 . The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A virus in late September and early October. The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion. Bishop John Folda (pictured) of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A . State Immunization Program Manager Molly Howell says the risk is low, but officials feel it's important to alert people to the possible exposure. The diocese announced on Monday that Bishop John Folda is taking time off after being diagnosed with hepatitis A. The diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in Italy last month. Symptoms of hepatitis A include fever, tiredness, loss of appetite, nausea and abdominal discomfort. Fargo Catholic Diocese in North Dakota (pictured) is where the bishop is located .\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article1 = train_dataset[\"train\"][1][\"1\"]\n",
    "article1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f707e9b-076b-4993-8a18-8160165e8b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bishop John Folda, of North Dakota, is taking time off after being diagnosed .\\nHe contracted the infection through contaminated food in Italy .\\nChurch members in Fargo, Grand Forks and Jamestown could have been exposed .'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highlights1 = train_dataset[\"train\"][1][\"2\"]\n",
    "highlights1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f5370cf-16f3-429e-bc84-6f27a6540250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'Bishop',\n",
       " 'John',\n",
       " 'F',\n",
       " '##old',\n",
       " '##a',\n",
       " ',',\n",
       " 'of',\n",
       " 'North',\n",
       " 'Dakota',\n",
       " ',',\n",
       " 'is',\n",
       " 'taking',\n",
       " 'time',\n",
       " 'off',\n",
       " 'after',\n",
       " 'being',\n",
       " 'diagnosed',\n",
       " '.',\n",
       " 'He',\n",
       " 'contracted',\n",
       " 'the',\n",
       " 'infection',\n",
       " 'through',\n",
       " 'contaminated',\n",
       " 'food',\n",
       " 'in',\n",
       " 'Italy',\n",
       " '.',\n",
       " 'Church',\n",
       " 'members',\n",
       " 'in',\n",
       " 'Fargo',\n",
       " ',',\n",
       " 'Grand',\n",
       " 'Fork',\n",
       " '##s',\n",
       " 'and',\n",
       " 'James',\n",
       " '##town',\n",
       " 'could',\n",
       " 'have',\n",
       " 'been',\n",
       " 'exposed',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = tokenizer(text_target=highlights1)\n",
    "tokenizer.convert_ids_to_tokens(targets['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b8a0415-de86-4b05-afa9-d7edc50a83da",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = maxinput_tokens\n",
    "max_target_length = maxoutput_tokens\n",
    "\n",
    "def preprocess_function(batch):\n",
    "    model_inputs = tokenizer(\n",
    "        batch['1'], max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Set up the tokenizer for targets\n",
    "    labels = tokenizer(\n",
    "        text_target=batch['2'], max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac530761-bb6e-4f37-be14-81e2b9871c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "babb9ed558304b41a7fa2f5447d71eb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = train_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=train_dataset[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2525b3d4-a00a-432a-860b-358c900647cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04f8a310-0515-4226-826a-7d5fdba49545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e28654f5244f46b8aea5d5a8904b1406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets_test = test_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=test_dataset[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a864c93-7412-437b-af85-307144e67633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1509e2c2-a86c-41ed-ba7f-bfc2984f8709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "960ba538-3bc0-4862-90d5-5e7f958c66bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(0, 5)])\n",
    "batch.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a22bc4a-776f-4c19-a144-fe448a34cc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  3342,   102,  ...,     0,     0,     0],\n",
       "        [  101,  1650,   119,  ...,     0,     0,     0],\n",
       "        [  101,   113, 13597,  ...,     0,     0,     0],\n",
       "        [  101,   138,  6882,  ...,  2774,   119,   102],\n",
       "        [  101,   113, 13597,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_ids']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88906053-232e-4ea4-bc6b-1d5f7428f446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['attention_mask']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6086204-0e5b-4366-99d0-b1f1ae42d9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 12976,   102,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100],\n",
       "        [  101,  3167,  1287,   143, 11015,  1161,   117,  1104,  1456,  7241,\n",
       "           117,  1110,  1781,  1159,  1228,  1170,  1217, 11534,   119,  1124,\n",
       "         11058,  1103,  8974,  1194, 21636,  2094,  1107,  2413,   119,  1722,\n",
       "          1484,  1107, 25727,   117,  2224, 16384,  1116,  1105,  1600,  3305,\n",
       "          1180,  1138,  1151,  5490,   119,   102,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100],\n",
       "        [  101, 10382, 12522,   131,  3291,  1643,  1215,  1117,  1648,  1106,\n",
       "          1494, 18316,  3404,  8811,   119,  6197, 28044,   117,  1126,  4422,\n",
       "          5707,  6403,   117,  9273,  2375,  1372,  1243,  3832,   119,  1124,\n",
       "          1145,  4768,  1106,  2653,  1160, 27459,  1107,   170,  3513,  4928,\n",
       "           117,   170, 12522,  1155, 27487,  1116,   119,   102,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100],\n",
       "        [  101,  6422,   142, 19515,  2897,  1633,   118,  6365,   117,  1765,\n",
       "           117,  1125,  6882,  1120,  1655,  1210, 10473,  2145,  1196,  3759,\n",
       "          1610,   119,  3982,  1606,  2179,  1165,  1119,  1396,  5686,  1506,\n",
       "          1812,  1107, 14680,  9019, 16397,   117,  8843,  1104, 23721,   119,\n",
       "         21229,  1174,  1246,   118,  1113,  1154,  1743,   118,  1214,   118,\n",
       "          1385,  4858, 11772,  1183,   112,   188,  1610,   117,  1150,  1452,\n",
       "          1107,  2704,   119,  3284,  1474,  1119,  1156,  1138,  1151,  1166,\n",
       "          2732,  3668,   118,  2797,  5310,  1120,  1159,  1104,  5683,   119,\n",
       "          1124,  1108,  1276,  5425,  1120, 10867,  5373,  2031,  1104,  3989,\n",
       "          1473,  1118,  4249,  3759,   119,   102],\n",
       "        [  101,  9394, 18463, 11064,  1867,  1980,  1538,  1129,  2407,  1106,\n",
       "          4392, 19344,  1209,  2644,  1241,  3091,   119, 18525,  1158,  2733,\n",
       "           112,   188,  1671,  1661,  1156,  1129,  1141,  1236,  1104, 21718,\n",
       "         13044,  1147,  1619,  1111,  1697, 24489,   117,  1131,  1867,   119,\n",
       "          1252,  1131,  1867,  1980,  1156,  1138,   170,  1662,  1159,  3709,\n",
       "          1157, 11615,  1280,  1443,  1540,  1121,  1103,  1746,   119,   102,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0724f805-416f-4a3a-b35d-40c36dd178e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100, 102, 0, 101, 103]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a7960138-170a-4903-9d3f-8b9625b812c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b13c58c3-9e4e-4b8e-a64a-3fa205b3077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    tokenized_datasets_test[\"train\"],\n",
    "    batch_size=32,\n",
    "    collate_fn=data_collator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "222534cc-93b0-4b21-bea2-a68712312db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: input_ids v.shape: torch.Size([32, 1781])\n",
      "k: attention_mask v.shape: torch.Size([32, 1781])\n",
      "k: labels v.shape: torch.Size([32, 139])\n"
     ]
    }
   ],
   "source": [
    "# check how it works\n",
    "for batch in train_loader:\n",
    "  for k, v in batch.items():\n",
    "    print(\"k:\", k, \"v.shape:\", v.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4987975-ff8b-4e6b-946f-5e5f1931106e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28996"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "265b9afd-0e79-4918-82a4-dba499ff2271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'championship'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([2899])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9524eb78-c833-434e-ba19-e56ce28fd146",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4eb4fc7c-0c9a-47db-ab75-fdb84290b257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1a1c8438-598b-44e6-bfca-5decafc0ea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "  def __init__(self, d_k, d_model, n_heads, max_len, causal=False):\n",
    "    super().__init__()\n",
    "\n",
    "    # Assume d_v = d_k\n",
    "    self.d_k = d_k\n",
    "    self.n_heads = n_heads\n",
    "\n",
    "    self.key = nn.Linear(d_model, d_k * n_heads)\n",
    "    self.query = nn.Linear(d_model, d_k * n_heads)\n",
    "    self.value = nn.Linear(d_model, d_k * n_heads)\n",
    "\n",
    "    # final linear layer\n",
    "    self.fc = nn.Linear(d_k * n_heads, d_model)\n",
    "\n",
    "    # causal mask\n",
    "    # make it so that diagonal is 0 too\n",
    "    # this way we don't have to shift the inputs to make targets\n",
    "    self.causal = causal\n",
    "    if causal:\n",
    "      cm = torch.tril(torch.ones(max_len, max_len))\n",
    "      self.register_buffer(\n",
    "          \"causal_mask\",\n",
    "          cm.view(1, 1, max_len, max_len)\n",
    "      )\n",
    "\n",
    "  def forward(self, q, k, v, pad_mask=None):\n",
    "    q = self.query(q) # N x T x (hd_k)\n",
    "    k = self.key(k)   # N x T x (hd_k)\n",
    "    v = self.value(v) # N x T x (hd_v)\n",
    "\n",
    "    N = q.shape[0]\n",
    "    T_output = q.shape[1]\n",
    "    T_input = k.shape[1]\n",
    "\n",
    "    # change the shape to:\n",
    "    # (N, T, h, d_k) -> (N, h, T, d_k)\n",
    "    # in order for matrix multiply to work properly\n",
    "    q = q.view(N, T_output, self.n_heads, self.d_k).transpose(1, 2)\n",
    "    k = k.view(N, T_input, self.n_heads, self.d_k).transpose(1, 2)\n",
    "    v = v.view(N, T_input, self.n_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "    # compute attention weights\n",
    "    # (N, h, T, d_k) x (N, h, d_k, T) --> (N, h, T, T)\n",
    "    attn_scores = q @ k.transpose(-2, -1) / math.sqrt(self.d_k)\n",
    "    if pad_mask is not None:\n",
    "      attn_scores = attn_scores.masked_fill(\n",
    "          pad_mask[:, None, None, :] == 0, float('-inf'))\n",
    "    if self.causal:\n",
    "      attn_scores = attn_scores.masked_fill(\n",
    "          self.causal_mask[:, :, :T_output, :T_input] == 0, float('-inf'))\n",
    "    attn_weights = F.softmax(attn_scores, dim=-1)\n",
    "    \n",
    "    # compute attention-weighted values\n",
    "    # (N, h, T, T) x (N, h, T, d_k) --> (N, h, T, d_k)\n",
    "    A = attn_weights @ v\n",
    "\n",
    "    # reshape it back before final linear layer\n",
    "    A = A.transpose(1, 2) # (N, T, h, d_k)\n",
    "    A = A.contiguous().view(N, T_output, self.d_k * self.n_heads) # (N, T, h*d_k)\n",
    "\n",
    "    # projection\n",
    "    return self.fc(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "39582b87-80f5-46e8-97f1-8fc35101d71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "  def __init__(self, d_k, d_model, n_heads, max_len, dropout_prob=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.ln1 = nn.LayerNorm(d_model)\n",
    "    self.ln2 = nn.LayerNorm(d_model)\n",
    "    self.mha = MultiHeadAttention(d_k, d_model, n_heads, max_len, causal=False)\n",
    "    self.ann = nn.Sequential(\n",
    "        nn.Linear(d_model, d_model * 4),\n",
    "        nn.GELU(),\n",
    "        nn.Linear(d_model * 4, d_model),\n",
    "        nn.Dropout(dropout_prob),\n",
    "    )\n",
    "    self.dropout = nn.Dropout(p=dropout_prob)\n",
    "  \n",
    "  def forward(self, x, pad_mask=None):\n",
    "    x = self.ln1(x + self.mha(x, x, x, pad_mask))\n",
    "    x = self.ln2(x + self.ann(x))\n",
    "    x = self.dropout(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5f1d96c7-4264-4a4a-a31b-b590ced48f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "  def __init__(self, d_k, d_model, n_heads, max_len, dropout_prob=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.ln1 = nn.LayerNorm(d_model)\n",
    "    self.ln2 = nn.LayerNorm(d_model)\n",
    "    self.ln3 = nn.LayerNorm(d_model)\n",
    "    self.mha1 = MultiHeadAttention(d_k, d_model, n_heads, max_len, causal=True)\n",
    "    self.mha2 = MultiHeadAttention(d_k, d_model, n_heads, max_len, causal=False)\n",
    "    self.ann = nn.Sequential(\n",
    "        nn.Linear(d_model, d_model * 4),\n",
    "        nn.GELU(),\n",
    "        nn.Linear(d_model * 4, d_model),\n",
    "        nn.Dropout(dropout_prob),\n",
    "    )\n",
    "    self.dropout = nn.Dropout(p=dropout_prob)\n",
    "  \n",
    "  def forward(self, enc_output, dec_input, enc_mask=None, dec_mask=None):\n",
    "    # self-attention on decoder input\n",
    "    x = self.ln1(\n",
    "        dec_input + self.mha1(dec_input, dec_input, dec_input, dec_mask))\n",
    "\n",
    "    # multi-head attention including encoder output\n",
    "    x = self.ln2(x + self.mha2(x, enc_output, enc_output, enc_mask))\n",
    "\n",
    "    x = self.ln3(x + self.ann(x))\n",
    "    x = self.dropout(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a32e10cd-d19f-4e95-b1c2-504a55506bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "  def __init__(self, d_model, max_len=2048, dropout_prob=0.1):\n",
    "    super().__init__()\n",
    "    self.dropout = nn.Dropout(p=dropout_prob)\n",
    "\n",
    "    position = torch.arange(max_len).unsqueeze(1)\n",
    "    exp_term = torch.arange(0, d_model, 2)\n",
    "    div_term = torch.exp(exp_term * (-math.log(10000.0) / d_model))\n",
    "    pe = torch.zeros(1, max_len, d_model)\n",
    "    pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "    pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "    self.register_buffer('pe', pe)\n",
    "\n",
    "  def forward(self, x):\n",
    "    # x.shape: N x T x D\n",
    "    x = x + self.pe[:, :x.size(1), :]\n",
    "    return self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7985e3a6-d08e-43b7-854d-3898da0f278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "  def __init__(self,\n",
    "               vocab_size,\n",
    "               max_len,\n",
    "               d_k,\n",
    "               d_model,\n",
    "               n_heads,\n",
    "               n_layers,\n",
    "              #  n_classes,\n",
    "               dropout_prob):\n",
    "    super().__init__()\n",
    "\n",
    "    self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "    self.pos_encoding = PositionalEncoding(d_model, max_len, dropout_prob)\n",
    "    transformer_blocks = [\n",
    "        EncoderBlock(\n",
    "            d_k,\n",
    "            d_model,\n",
    "            n_heads,\n",
    "            max_len,\n",
    "            dropout_prob) for _ in range(n_layers)]\n",
    "    self.transformer_blocks = nn.Sequential(*transformer_blocks)\n",
    "    self.ln = nn.LayerNorm(d_model)\n",
    "    # self.fc = nn.Linear(d_model, n_classes)\n",
    "  \n",
    "  def forward(self, x, pad_mask=None):\n",
    "    x = self.embedding(x)\n",
    "    x = self.pos_encoding(x)\n",
    "    for block in self.transformer_blocks:\n",
    "      x = block(x, pad_mask)\n",
    "\n",
    "    # many-to-one (x has the shape N x T x D)\n",
    "    # x = x[:, 0, :]\n",
    "\n",
    "    x = self.ln(x)\n",
    "    # x = self.fc(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "251df2eb-cf00-4a6e-a6a9-4eabc2b2bfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self,\n",
    "               vocab_size,\n",
    "               max_len,\n",
    "               d_k,\n",
    "               d_model,\n",
    "               n_heads,\n",
    "               n_layers,\n",
    "               dropout_prob):\n",
    "    super().__init__()\n",
    "\n",
    "    self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "    self.pos_encoding = PositionalEncoding(d_model, max_len, dropout_prob)\n",
    "    transformer_blocks = [\n",
    "        DecoderBlock(\n",
    "            d_k,\n",
    "            d_model,\n",
    "            n_heads,\n",
    "            max_len,\n",
    "            dropout_prob) for _ in range(n_layers)]\n",
    "    self.transformer_blocks = nn.Sequential(*transformer_blocks)\n",
    "    self.ln = nn.LayerNorm(d_model)\n",
    "    self.fc = nn.Linear(d_model, vocab_size)\n",
    "  \n",
    "  def forward(self, enc_output, dec_input, enc_mask=None, dec_mask=None):\n",
    "    x = self.embedding(dec_input)\n",
    "    x = self.pos_encoding(x)\n",
    "    for block in self.transformer_blocks:\n",
    "      x = block(enc_output, x, enc_mask, dec_mask)\n",
    "    x = self.ln(x)\n",
    "    x = self.fc(x) # many-to-many\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8827b8b0-385e-44a6-96f5-ac67edb3b7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "  def __init__(self, encoder, decoder):\n",
    "    super().__init__()\n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "  \n",
    "  def forward(self, enc_input, dec_input, enc_mask, dec_mask):\n",
    "    enc_output = self.encoder(enc_input, enc_mask)\n",
    "    dec_output = self.decoder(enc_output, dec_input, enc_mask, dec_mask)\n",
    "    return dec_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48132b2-b4f0-4ae5-9c22-fbd62c95ff89",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "182cfb8c-9b8c-4076-a1c9-7064322c76cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test it\n",
    "encoder = Encoder(vocab_size=tokenizer.vocab_size,\n",
    "                  max_len=maxinput_tokens,\n",
    "                  d_k=16,\n",
    "                  d_model=64,\n",
    "                  n_heads=4,\n",
    "                  n_layers=2,\n",
    "                  dropout_prob=0.1)\n",
    "decoder = Decoder(vocab_size=tokenizer.vocab_size,\n",
    "                  max_len=maxoutput_tokens,\n",
    "                  d_k=16,\n",
    "                  d_model=64,\n",
    "                  n_heads=4,\n",
    "                  n_layers=2,\n",
    "                  dropout_prob=0.1)\n",
    "transformer = Transformer(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "57ffcadb-b1c1-4a47-a0a5-4e80c2c01a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (embedding): Embedding(28996, 64)\n",
       "  (pos_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer_blocks): Sequential(\n",
       "    (0): DecoderBlock(\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha1): MultiHeadAttention(\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (mha2): MultiHeadAttention(\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (ann): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): DecoderBlock(\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha1): MultiHeadAttention(\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (mha2): MultiHeadAttention(\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (ann): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc): Linear(in_features=64, out_features=28996, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c770c4ea-2019-4873-b443-7481dc4bce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "optimizer = torch.optim.Adam(transformer.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "884916cb-c5f1-4aa3-b897-83ed18cca24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# A function to encapsulate the training loop\n",
    "def train(model, criterion, optimizer, train_loader, valid_loader, epochs):\n",
    "  train_losses = np.zeros(epochs)\n",
    "  test_losses = np.zeros(epochs)\n",
    "\n",
    "  for it in range(epochs):\n",
    "    model.train()\n",
    "    t0 = datetime.now()\n",
    "    train_loss = []\n",
    "    for batch in train_loader:\n",
    "      # move data to GPU (enc_input, enc_mask, translation)\n",
    "      batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "      # zero the parameter gradients\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      enc_input = batch['input_ids']\n",
    "      enc_mask = batch['attention_mask']\n",
    "      targets = batch['labels']\n",
    "\n",
    "      # shift targets forwards to get decoder_input\n",
    "      dec_input = targets.clone().detach()\n",
    "      dec_input = torch.roll(dec_input, shifts=1, dims=1)\n",
    "      dec_input[:, 0] = 101\n",
    "\n",
    "      # also convert all -100 to pad token id\n",
    "      dec_input = dec_input.masked_fill(\n",
    "          dec_input == -100, tokenizer.pad_token_id)\n",
    "\n",
    "      # make decoder input mask\n",
    "      dec_mask = torch.ones_like(dec_input)\n",
    "      dec_mask = dec_mask.masked_fill(dec_input == tokenizer.pad_token_id, 0)\n",
    "\n",
    "      # Forward pass\n",
    "      outputs = model(enc_input, dec_input, enc_mask, dec_mask)\n",
    "      loss = criterion(outputs.transpose(2, 1), targets)\n",
    "        \n",
    "      # Backward and optimize\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      train_loss.append(loss.item())\n",
    "\n",
    "    # Get train loss and test loss\n",
    "    train_loss = np.mean(train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = []\n",
    "    for batch in valid_loader:\n",
    "      batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "      enc_input = batch['input_ids']\n",
    "      enc_mask = batch['attention_mask']\n",
    "      targets = batch['labels']\n",
    "\n",
    "      # shift targets forwards to get decoder_input\n",
    "      dec_input = targets.clone().detach()\n",
    "      dec_input = torch.roll(dec_input, shifts=1, dims=1)\n",
    "      dec_input[:, 0] = 101\n",
    "\n",
    "      # change -100s to regular padding\n",
    "      dec_input = dec_input.masked_fill(\n",
    "          dec_input == -100, tokenizer.pad_token_id)\n",
    "\n",
    "      # make decoder input mask\n",
    "      dec_mask = torch.ones_like(dec_input)\n",
    "      dec_mask = dec_mask.masked_fill(dec_input == tokenizer.pad_token_id, 0)\n",
    "\n",
    "      outputs = model(enc_input, dec_input, enc_mask, dec_mask)\n",
    "      loss = criterion(outputs.transpose(2, 1), targets)\n",
    "      test_loss.append(loss.item())\n",
    "    test_loss = np.mean(test_loss)\n",
    "\n",
    "    # Save losses\n",
    "    train_losses[it] = train_loss\n",
    "    test_losses[it] = test_loss\n",
    "    \n",
    "    dt = datetime.now() - t0\n",
    "    print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, \\\n",
    "      Test Loss: {test_loss:.4f}, Duration: {dt}')\n",
    "  \n",
    "  return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "221cabac-f732-498a-bf17-d13087d6c2cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.61 GiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 6.28 GiB is allocated by PyTorch, and 3.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_losses, test_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[52], line 40\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, train_loader, valid_loader, epochs)\u001b[0m\n\u001b[1;32m     37\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m), targets)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Backward and optimize\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     42\u001b[0m train_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.61 GiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 6.28 GiB is allocated by PyTorch, and 3.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "train_losses, test_losses = train(\n",
    "    transformer, criterion, optimizer, train_loader, valid_loader, epochs=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffbc113-9f36-481e-9d38-fadbbd61fd81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85969175-48d7-430e-a5f0-73776efa9e94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263b793b-37c6-4d83-bf37-89a24f8d98df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02b5054-989f-4c70-bdb1-9ddb5e73dec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097a07b3-a6dc-4f32-aef7-ce486334977b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xe = np.random.randint(0, 20_000, size=(8, 512))\n",
    "xe_t = torch.tensor(xe).to(device)\n",
    "\n",
    "xd = np.random.randint(0, 10_000, size=(8, 256))\n",
    "xd_t = torch.tensor(xd).to(device)\n",
    "\n",
    "maske = np.ones((8, 512))\n",
    "maske[:, 256:] = 0\n",
    "maske_t = torch.tensor(maske).to(device)\n",
    "\n",
    "maskd = np.ones((8, 256))\n",
    "maskd[:, 128:] = 0\n",
    "maskd_t = torch.tensor(maskd).to(device)\n",
    "\n",
    "out = transformer(xe_t, xd_t, maske_t, maskd_t)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e79182-2c08-4ccc-a800-7e4ca56626e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837770ea-1933-4f6c-81de-1aae6ad78b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://lazyprogrammer.me/course_files/nlp3/spa.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff28450-1990-4a9a-a603-4e3776128fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head spa.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe03718-c635-4b27-8eb3-d3cec668ce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('spa.txt', sep=\"\\t\", header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5ac2a8-1362-473d-96b7-ba558e2a24a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb10493-2ebb-4e78-a203-3ed892c99251",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:30_000] # takes too long\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c5105b-87e6-45d6-a380-1e7b0eb14720",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['en', 'es']\n",
    "df.to_csv('spa.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ba7492-4ad0-49fc-847c-b0515d6798a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head spa.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920aa856-03c1-4246-9977-f32747ae1cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets sentencepiece sacremoses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b671983-03a8-4af4-8665-e7c62df2d7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "raw_dataset = load_dataset('csv', data_files='spa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd99f29-3aff-4a9f-8ab8-2b9a5c15f6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41031af-ca52-4d78-be4e-82149e1e85a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = raw_dataset['train'].train_test_split(test_size=0.3, seed=42)\n",
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cc5c9f-b2bd-4438-982a-ccba62b15b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"Helsinki-NLP/opus-mt-en-es\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d266f6-8183-4624-b009-6b7f5d37388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_sentence = split[\"train\"][0][\"en\"]\n",
    "es_sentence = split[\"train\"][0][\"es\"]\n",
    "\n",
    "inputs = tokenizer(en_sentence)\n",
    "targets = tokenizer(text_target=es_sentence)\n",
    "\n",
    "tokenizer.convert_ids_to_tokens(targets['input_ids'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d600aad1-adbd-4d29-8c60-e6bb4190050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f52ad9-ce50-467b-8f43-a7a07098f539",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "\n",
    "def preprocess_function(batch):\n",
    "    model_inputs = tokenizer(\n",
    "        batch['en'], max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Set up the tokenizer for targets\n",
    "    labels = tokenizer(\n",
    "        text_target=batch['es'], max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bf838a-f325-4b75-8fd0-b40cdf96eaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = split.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=split[\"train\"].column_names,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c817541-aa1f-4bbd-ab25-918ddc6a9a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb91e842-9df7-45ff-9c90-b055c3716938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82711a3c-155a-4611-95f8-fe491dd572fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(0, 5)])\n",
    "batch.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bafa28-9fc6-4b3d-926f-a8da60084fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['input_ids']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b827bd02-2175-40a6-89a7-ded746416147",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['attention_mask']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e8c446-330b-44b7-89ac-edaf76f0b894",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d25743b-915c-4c47-a9f8-2126d79af7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.all_special_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592d2839-abc4-4e2a-ae06-82c98c5b1eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.all_special_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9990da0c-bb87-4e92-9a1e-69f504d203fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer('<pad>')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95990cba-b9be-4b81-bfab-e207f2bafd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    tokenized_datasets[\"test\"],\n",
    "    batch_size=32,\n",
    "    collate_fn=data_collator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c7c52b-d055-40a3-8bae-a07733fee549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2625fe5b-069f-49b3-b7d1-294153b83387",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://deeplearningcourses.com/notebooks/YROaDO6P4h3GNPYKYNlWjA/mHntSDrJRP9_eMCl7KMl6w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Kernel",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
